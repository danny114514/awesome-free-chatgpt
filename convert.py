import json
import re
from concurrent.futures import ThreadPoolExecutor

# è¯»å–README.mdæ–‡ä»¶çš„å†…å®¹
with open("README.md", "r", encoding="utf-8") as file:
    content = file.read()
    # å½“è¯»å–åˆ°åŒ…å«'### ğŸš« å·²å¤±æ•ˆ'çš„è¡Œæ—¶åœæ­¢è¯»å–
    content = content.split('<tbody>')[1]
    content = content.split('</tbody>')[0]
    content = re.sub(r'\s+', ' ', content).strip()
#print(content)
pattern = re.compile(r'<tr.*?>(.*?)<\/tr>')
urls = pattern.findall(content)
print(urls[0])
#pattern = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+(?=\])')
# åœ¨å†…å®¹ä¸­æ‰¾åˆ°æ‰€æœ‰çš„URL
#urls = pattern.findall(content)
# ç§»é™¤URLæœ«å°¾çš„'/'å¹¶åˆå¹¶ç›¸åŒçš„URL
unique_urls = []
def det_sine(html):
    p = re.compile(r'<td>(\d+)</td>\s*<td>\s*<a href="([^"]+)" target="_blank">[^<]+</a>\s*<br>\s*</td>\s*<td>\s*([\W\s]+)\s*</td>\s*<td>(\d{4}-\d{2}-\d{2})</td>')
    p = p.findall(html)
    return p
for i in urls:
    unique_urls.append(det_sine(i))
    urls = []
for i in unique_urls:
    for h in i:
        h=list(h)
        h[2] = re.sub(r'\s+', '',h[2])
        urls.append(h)

print(urls)
"""
for url in urls:
    url = url[:-1] if url.endswith('/') else url
    if url not in unique_urls:
        unique_urls.append(url)
print(unique_urls)
"""
# å°†URLä¿å­˜åˆ°urls.jsonæ–‡ä»¶ä¸­
with open("urls.json", "w") as file:
    json.dump(urls, file,indent=4)
